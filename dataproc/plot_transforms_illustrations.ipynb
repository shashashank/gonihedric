{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "# Illustration of transforms\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>Try on [Colab](https://colab.research.google.com/github/pytorch/vision/blob/gh-pages/main/_generated_ipynb_notebooks/plot_transforms_illustrations.ipynb)\n",
        "    or `go to the end <sphx_glr_download_auto_examples_transforms_plot_transforms_illustrations.py>` to download the full example code.</p></div>\n",
        "\n",
        "This example illustrates some of the various transforms available in `the\n",
        "torchvision.transforms.v2 module <transforms>`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": false
      },
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'plot' from 'helpers' (/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/helpers/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     12\u001b[39m torch.manual_seed(\u001b[32m0\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# If you're trying to run that on Colab, you can download the assets and the\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# helpers from https://github.com/pytorch/vision/tree/main/gallery/\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhelpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot\n\u001b[32m     17\u001b[39m orig_img = Image.open(Path(\u001b[33m'\u001b[39m\u001b[33m../assets\u001b[39m\u001b[33m'\u001b[39m) / \u001b[33m'\u001b[39m\u001b[33mastronaut.jpg\u001b[39m\u001b[33m'\u001b[39m)\n",
            "\u001b[31mImportError\u001b[39m: cannot import name 'plot' from 'helpers' (/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/helpers/__init__.py)"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from torchvision.transforms import v2\n",
        "\n",
        "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
        "\n",
        "# if you change the seed, make sure that the randomly-applied transforms\n",
        "# properly show that the image can be both transformed and *not* transformed!\n",
        "torch.manual_seed(0)\n",
        "\n",
        "# If you're trying to run that on Colab, you can download the assets and the\n",
        "# helpers from https://github.com/pytorch/vision/tree/main/gallery/\n",
        "from helpers import plot\n",
        "orig_img = Image.open(Path('../assets') / 'astronaut.jpg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Geometric Transforms\n",
        "Geometric image transformation refers to the process of altering the geometric properties of an image,\n",
        "such as its shape, size, orientation, or position.\n",
        "It involves applying mathematical operations to the image pixels or coordinates to achieve the desired transformation.\n",
        "\n",
        "### Pad\n",
        "The :class:`~torchvision.transforms.Pad` transform\n",
        "(see also :func:`~torchvision.transforms.functional.pad`)\n",
        "pads all image borders with some pixel values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "padded_imgs = [v2.Pad(padding=padding)(orig_img) for padding in (3, 10, 30, 50)]\n",
        "plot([orig_img] + padded_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Resize\n",
        "The :class:`~torchvision.transforms.Resize` transform\n",
        "(see also :func:`~torchvision.transforms.functional.resize`)\n",
        "resizes an image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "resized_imgs = [v2.Resize(size=size)(orig_img) for size in (30, 50, 100, orig_img.size)]\n",
        "plot([orig_img] + resized_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### CenterCrop\n",
        "The :class:`~torchvision.transforms.CenterCrop` transform\n",
        "(see also :func:`~torchvision.transforms.functional.center_crop`)\n",
        "crops the given image at the center.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "center_crops = [v2.CenterCrop(size=size)(orig_img) for size in (30, 50, 100, orig_img.size)]\n",
        "plot([orig_img] + center_crops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### FiveCrop\n",
        "The :class:`~torchvision.transforms.FiveCrop` transform\n",
        "(see also :func:`~torchvision.transforms.functional.five_crop`)\n",
        "crops the given image into four corners and the central crop.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "(top_left, top_right, bottom_left, bottom_right, center) = v2.FiveCrop(size=(100, 100))(orig_img)\n",
        "plot([orig_img] + [top_left, top_right, bottom_left, bottom_right, center])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomPerspective\n",
        "The :class:`~torchvision.transforms.RandomPerspective` transform\n",
        "(see also :func:`~torchvision.transforms.functional.perspective`)\n",
        "performs random perspective transform on an image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "perspective_transformer = v2.RandomPerspective(distortion_scale=0.6, p=1.0)\n",
        "perspective_imgs = [perspective_transformer(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + perspective_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomRotation\n",
        "The :class:`~torchvision.transforms.RandomRotation` transform\n",
        "(see also :func:`~torchvision.transforms.functional.rotate`)\n",
        "rotates an image with random angle.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "rotater = v2.RandomRotation(degrees=(0, 180))\n",
        "rotated_imgs = [rotater(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + rotated_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomAffine\n",
        "The :class:`~torchvision.transforms.RandomAffine` transform\n",
        "(see also :func:`~torchvision.transforms.functional.affine`)\n",
        "performs random affine transform on an image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "affine_transfomer = v2.RandomAffine(degrees=(30, 70), translate=(0.1, 0.3), scale=(0.5, 0.75))\n",
        "affine_imgs = [affine_transfomer(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + affine_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ElasticTransform\n",
        "The :class:`~torchvision.transforms.ElasticTransform` transform\n",
        "(see also :func:`~torchvision.transforms.functional.elastic_transform`)\n",
        "Randomly transforms the morphology of objects in images and produces a\n",
        "see-through-water-like effect.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "elastic_transformer = v2.ElasticTransform(alpha=250.0)\n",
        "transformed_imgs = [elastic_transformer(orig_img) for _ in range(2)]\n",
        "plot([orig_img] + transformed_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomCrop\n",
        "The :class:`~torchvision.transforms.RandomCrop` transform\n",
        "(see also :func:`~torchvision.transforms.functional.crop`)\n",
        "crops an image at a random location.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "cropper = v2.RandomCrop(size=(128, 128))\n",
        "crops = [cropper(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + crops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomResizedCrop\n",
        "The :class:`~torchvision.transforms.RandomResizedCrop` transform\n",
        "(see also :func:`~torchvision.transforms.functional.resized_crop`)\n",
        "crops an image at a random location, and then resizes the crop to a given\n",
        "size.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "resize_cropper = v2.RandomResizedCrop(size=(32, 32))\n",
        "resized_crops = [resize_cropper(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + resized_crops)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Photometric Transforms\n",
        "Photometric image transformation refers to the process of modifying the photometric properties of an image,\n",
        "such as its brightness, contrast, color, or tone.\n",
        "These transformations are applied to change the visual appearance of an image\n",
        "while preserving its geometric structure.\n",
        "\n",
        "Except :class:`~torchvision.transforms.Grayscale`, the following transforms are random,\n",
        "which means that the same transform\n",
        "instance will produce different result each time it transforms a given image.\n",
        "\n",
        "### Grayscale\n",
        "The :class:`~torchvision.transforms.Grayscale` transform\n",
        "(see also :func:`~torchvision.transforms.functional.to_grayscale`)\n",
        "converts an image to grayscale\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "gray_img = v2.Grayscale()(orig_img)\n",
        "plot([orig_img, gray_img], cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ColorJitter\n",
        "The :class:`~torchvision.transforms.ColorJitter` transform\n",
        "randomly changes the brightness, contrast, saturation, hue, and other properties of an image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "jitter = v2.ColorJitter(brightness=.5, hue=.3)\n",
        "jittered_imgs = [jitter(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + jittered_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GaussianBlur\n",
        "The :class:`~torchvision.transforms.GaussianBlur` transform\n",
        "(see also :func:`~torchvision.transforms.functional.gaussian_blur`)\n",
        "performs gaussian blur transform on an image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "blurrer = v2.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 5.))\n",
        "blurred_imgs = [blurrer(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + blurred_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomInvert\n",
        "The :class:`~torchvision.transforms.RandomInvert` transform\n",
        "(see also :func:`~torchvision.transforms.functional.invert`)\n",
        "randomly inverts the colors of the given image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "inverter = v2.RandomInvert()\n",
        "invertered_imgs = [inverter(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + invertered_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomPosterize\n",
        "The :class:`~torchvision.transforms.RandomPosterize` transform\n",
        "(see also :func:`~torchvision.transforms.functional.posterize`)\n",
        "randomly posterizes the image by reducing the number of bits\n",
        "of each color channel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "posterizer = v2.RandomPosterize(bits=2)\n",
        "posterized_imgs = [posterizer(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + posterized_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomSolarize\n",
        "The :class:`~torchvision.transforms.RandomSolarize` transform\n",
        "(see also :func:`~torchvision.transforms.functional.solarize`)\n",
        "randomly solarizes the image by inverting all pixel values above\n",
        "the threshold.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "solarizer = v2.RandomSolarize(threshold=192.0)\n",
        "solarized_imgs = [solarizer(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + solarized_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomAdjustSharpness\n",
        "The :class:`~torchvision.transforms.RandomAdjustSharpness` transform\n",
        "(see also :func:`~torchvision.transforms.functional.adjust_sharpness`)\n",
        "randomly adjusts the sharpness of the given image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sharpness_adjuster = v2.RandomAdjustSharpness(sharpness_factor=2)\n",
        "sharpened_imgs = [sharpness_adjuster(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + sharpened_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomAutocontrast\n",
        "The :class:`~torchvision.transforms.RandomAutocontrast` transform\n",
        "(see also :func:`~torchvision.transforms.functional.autocontrast`)\n",
        "randomly applies autocontrast to the given image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "autocontraster = v2.RandomAutocontrast()\n",
        "autocontrasted_imgs = [autocontraster(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + autocontrasted_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomEqualize\n",
        "The :class:`~torchvision.transforms.RandomEqualize` transform\n",
        "(see also :func:`~torchvision.transforms.functional.equalize`)\n",
        "randomly equalizes the histogram of the given image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "equalizer = v2.RandomEqualize()\n",
        "equalized_imgs = [equalizer(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + equalized_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### JPEG\n",
        "The :class:`~torchvision.transforms.v2.JPEG` transform\n",
        "(see also :func:`~torchvision.transforms.v2.functional.jpeg`)\n",
        "applies JPEG compression to the given image with random\n",
        "degree of compression.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "jpeg = v2.JPEG((5, 50))\n",
        "jpeg_imgs = [jpeg(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + jpeg_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augmentation Transforms\n",
        "The following transforms are combinations of multiple transforms,\n",
        "either geometric or photometric, or both.\n",
        "\n",
        "### AutoAugment\n",
        "The :class:`~torchvision.transforms.AutoAugment` transform\n",
        "automatically augments data based on a given auto-augmentation policy.\n",
        "See :class:`~torchvision.transforms.AutoAugmentPolicy` for the available policies.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "policies = [v2.AutoAugmentPolicy.CIFAR10, v2.AutoAugmentPolicy.IMAGENET, v2.AutoAugmentPolicy.SVHN]\n",
        "augmenters = [v2.AutoAugment(policy) for policy in policies]\n",
        "imgs = [\n",
        "    [augmenter(orig_img) for _ in range(4)]\n",
        "    for augmenter in augmenters\n",
        "]\n",
        "row_title = [str(policy).split('.')[-1] for policy in policies]\n",
        "plot([[orig_img] + row for row in imgs], row_title=row_title)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandAugment\n",
        "The :class:`~torchvision.transforms.RandAugment` is an alternate version of AutoAugment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "augmenter = v2.RandAugment()\n",
        "imgs = [augmenter(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TrivialAugmentWide\n",
        "The :class:`~torchvision.transforms.TrivialAugmentWide` is an alternate implementation of AutoAugment.\n",
        "However, instead of transforming an image multiple times, it transforms an image only once\n",
        "using a random transform from a given list with a random strength number.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "augmenter = v2.TrivialAugmentWide()\n",
        "imgs = [augmenter(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### AugMix\n",
        "The :class:`~torchvision.transforms.AugMix` transform interpolates between augmented versions of an image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "augmenter = v2.AugMix()\n",
        "imgs = [augmenter(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Randomly-applied Transforms\n",
        "\n",
        "The following transforms are randomly-applied given a probability ``p``.  That is, given ``p = 0.5``,\n",
        "there is a 50% chance to return the original image, and a 50% chance to return the transformed image,\n",
        "even when called with the same transform instance!\n",
        "\n",
        "### RandomHorizontalFlip\n",
        "The :class:`~torchvision.transforms.RandomHorizontalFlip` transform\n",
        "(see also :func:`~torchvision.transforms.functional.hflip`)\n",
        "performs horizontal flip of an image, with a given probability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hflipper = v2.RandomHorizontalFlip(p=0.5)\n",
        "transformed_imgs = [hflipper(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + transformed_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomVerticalFlip\n",
        "The :class:`~torchvision.transforms.RandomVerticalFlip` transform\n",
        "(see also :func:`~torchvision.transforms.functional.vflip`)\n",
        "performs vertical flip of an image, with a given probability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vflipper = v2.RandomVerticalFlip(p=0.5)\n",
        "transformed_imgs = [vflipper(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + transformed_imgs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RandomApply\n",
        "The :class:`~torchvision.transforms.RandomApply` transform\n",
        "randomly applies a list of transforms, with a given probability.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "applier = v2.RandomApply(transforms=[v2.RandomCrop(size=(64, 64))], p=0.5)\n",
        "transformed_imgs = [applier(orig_img) for _ in range(4)]\n",
        "plot([orig_img] + transformed_imgs)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "neuralnets",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
