{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e85b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as v2\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "from ray import tune, train\n",
    "import tempfile\n",
    "import torchDatasets as ds\n",
    "from ray.train import Checkpoint\n",
    "from ray.tune.schedulers import ASHAScheduler\n",
    "# from torchvision.models import resnet50, resnet18\n",
    "import networks as custNN\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cpu\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "\n",
    "modelName = \"Autoencoder\"; side = 32\n",
    "base_dir = '/home/shashank/Code/gonihedric/'; dataDir = base_dir + \"data/\"\n",
    "trainScheme = \"Autoencoder\"\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# class ConvAutoencoder(nn.Module):\n",
    "#     def __init__(self, latent_dim=8, dropout=0.2, internal_activaton=nn.ReLU(), output_activation=nn.Sigmoid()):\n",
    "#         super(ConvAutoencoder, self).__init__()\n",
    "\n",
    "#         self.drpt = nn.Dropout(dropout)\n",
    "\n",
    "#         # ----- Encoder -----\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1),  # -> (32, H/2, W/2)\n",
    "#             # nn.BatchNorm2d(32),\n",
    "#             internal_activaton,\n",
    "\n",
    "#             # nn.Dropout(dropout),\n",
    "#             nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), # -> (64, H/4, W/4)\n",
    "#             # nn.BatchNorm2d(64),\n",
    "#             internal_activaton,\n",
    "\n",
    "#             # nn.Dropout(dropout),\n",
    "#             nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),# -> (128, H/8, W/8)\n",
    "#             # nn.BatchNorm2d(128),\n",
    "#             internal_activaton,\n",
    "#         )\n",
    "\n",
    "#         # Bottleneck (latent space)\n",
    "#         self.fc_enc = nn.Linear(128 * 4 * 4, latent_dim)   # assumes input = 32x32\n",
    "#         self.fc_dec = nn.Linear(latent_dim, 128 * 4 * 4)\n",
    "\n",
    "#         # ----- Decoder -----\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             # nn.Dropout(dropout),\n",
    "#             nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1), # -> (64, H/4, W/4)\n",
    "#             # nn.BatchNorm2d(64),\n",
    "#             internal_activaton,\n",
    "\n",
    "#             # nn.Dropout(dropout),\n",
    "#             nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1), # -> (32, H/2, W/2)\n",
    "#             # nn.BatchNorm2d(32),\n",
    "#             internal_activaton,\n",
    "\n",
    "#             # nn.Dropout(dropout),\n",
    "#             nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),  # -> (1, H, W)\n",
    "#             output_activation\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Encode\n",
    "#         x = self.encoder(x)\n",
    "#         x = x.view(x.size(0), -1)      # flatten for FC\n",
    "#         x = self.drpt(x)\n",
    "#         z = self.fc_enc(x)\n",
    "\n",
    "#         # Decode\n",
    "#         z = self.drpt(z)\n",
    "#         x = self.fc_dec(z)\n",
    "#         x = x.view(x.size(0), 128, 4, 4)  # reshape back\n",
    "#         x = self.decoder(x)\n",
    "#         return x\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self, latent_dim=8, dropout=0.2):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "\n",
    "        self.drpt = nn.Dropout(dropout)\n",
    "\n",
    "        # ----- Encoder -----\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=2, padding=1, padding_mode='circular'),  # -> (32, H/2, W/2)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1), # -> (64, H/4, W/4)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),# -> (128, H/8, W/8)\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "\n",
    "        # Bottleneck (latent space)\n",
    "        self.fc_enc = nn.Linear(128 * 4 * 4, latent_dim)   # assumes input = 32x32\n",
    "        self.fc_dec = nn.Linear(latent_dim, 128 * 4 * 4)\n",
    "\n",
    "        # ----- Decoder -----\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1), # -> (64, H/4, W/4)\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1), # -> (32, H/2, W/2)\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.Dropout(dropout),\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=2, padding=1, output_padding=1),  # -> (1, H, W)\n",
    "            nn.Sigmoid()  # keeps output in [0,1] for binary images\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        x = self.encoder(x)\n",
    "        x = x.view(x.size(0), -1)      # flatten for FC\n",
    "        x = self.drpt(x)\n",
    "        z = self.fc_enc(x)\n",
    "\n",
    "        # Decode\n",
    "        z = self.drpt(z)\n",
    "        x = self.fc_dec(z)\n",
    "        x = x.view(x.size(0), 128, 4, 4)  # reshape back\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ReshapeTransform:\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "    def __call__(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "def load_data(data_dir, config):\n",
    "    # model, transform = custNN.modelPicker(modelName, side, nTargets, data_dir)\n",
    "    #paper = [900, 750, 600, 450, 300, 150, 75, 30, 10, 2]\n",
    "    # model = custNN.Autoencoder([900, 750, 600, 450, 300, 150, 75, 30, config[\"latentSpace\"]], nn.Sigmoid(), nn.Sigmoid())\n",
    "    # model = custNN.Autoencoder([1024, 750, 600, 450, 300, 150, 75, 30, 2], nn.ReLU(), nn.Sigmoid())\n",
    "    # # model = AutoencoderCNN(2)\n",
    "    model = ConvAutoencoder(config[\"latentSpace\"],0.2)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    else:\n",
    "        model = model.to(device)\n",
    "    \n",
    "    # transform = v2.Compose([v2.Lambda(lambda x: 2*x - 1)])\n",
    "    transform = v2.RandomVerticalFlip()\n",
    "    # transform = v2.Compose([v2.RandomHorizontalFlip(),\n",
    "    #                         v2.RandomVerticalFlip(),\n",
    "    #                         ReshapeTransform((1,side,side))])# None \n",
    "    trainset = ds.CustomAutoencoderDataset(data_dir+\"train2DGH32\", side, transform) # 2DGH32 gnhd2dTest\n",
    "    testset = ds.CustomAutoencoderDataset(data_dir+\"test2DGH32\", side, transform) # 2DGH32 gnhd2dTrain\n",
    "    return model, trainset, testset\n",
    "\n",
    "def initialize_weights(model):\n",
    "    nn.init.normal_(model.conv1.weight, 0, 0.1)\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.normal_(m.weight, 0, 0.1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def trainFN(config):\n",
    "\n",
    "    net, trainset, _ = load_data(dataDir, config)\n",
    "    custNN.initialize_weights(net)\n",
    "    \n",
    "    # optimizer = optim.SGD(net.parameters(),lr=config[\"lr\"],\n",
    "    #                       momentum=config[\"momentum\"],weight_decay=config[\"wd\"])\n",
    "    optimizer = optim.Adam(net.parameters(),lr=config[\"lr\"],weight_decay = config[\"wd\"])\n",
    "    # optimizer = optim.Adadelta(net.parameters(), lr=config[\"lr\"], weight_decay=config[\"wd\"])\n",
    "\n",
    "    exp_lr_scheduler = None# optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=config[\"gamma\"])\n",
    "\n",
    "    # Load existing checkpoint through `get_checkpoint()` API.\n",
    "    if train.get_checkpoint():\n",
    "        loaded_checkpoint = train.get_checkpoint()\n",
    "        with loaded_checkpoint.as_directory() as loaded_checkpoint_dir:\n",
    "            model_state, optimizer_state = torch.load(\n",
    "                os.path.join(loaded_checkpoint_dir, \"checkpoint.pt\")\n",
    "            )\n",
    "            net.load_state_dict(model_state)\n",
    "            optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "    test_abs = int(len(trainset) * 0.8)\n",
    "    train_subset, val_subset = random_split(\n",
    "        trainset, [test_abs, len(trainset) - test_abs])\n",
    "\n",
    "    trainloader = DataLoader( train_subset,\n",
    "                             batch_size=128,\n",
    "                             shuffle=True,\n",
    "                             num_workers=4)\n",
    "    valloader = DataLoader( val_subset,\n",
    "                           batch_size=128,\n",
    "                           shuffle=True,\n",
    "                           num_workers=4)\n",
    "\n",
    "    for epoch in range(50):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        epoch_steps = 0\n",
    "        net.train(); i = 0\n",
    "        for inputs,_ in trainloader:\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs = inputs.to(device)\n",
    "\n",
    "            optimizer.zero_grad() # zero the parameter gradients\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs).squeeze()\n",
    "            # outputs = outputs.float(); labels = labels.float()\n",
    "            loss = criterion(outputs, inputs.squeeze())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            epoch_steps += 1\n",
    "            if i % 2000 == 1999:  # print every 2000 mini-batches\n",
    "                print(\n",
    "                    \"[%d, %5d] loss: %.3f\"\n",
    "                    % (epoch + 1, i + 1, running_loss / epoch_steps)\n",
    "                )\n",
    "                epoch_steps = 0\n",
    "                running_loss = 0.0\n",
    "                if exp_lr_scheduler is not None:\n",
    "                    exp_lr_scheduler.step()\n",
    "            i += 1\n",
    "\n",
    "        # Validation loss\n",
    "        val_loss = 0.0\n",
    "        val_steps = 0\n",
    "        # correct = 0\n",
    "        net.eval()\n",
    "        with torch.no_grad():\n",
    "            for inputs,_ in valloader:\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = net(inputs)\n",
    "                outputs = outputs.detach().squeeze().float()\n",
    "                val_loss += criterion(outputs, inputs.squeeze()).cpu().numpy()\n",
    "                # predicted = torch.max(F.softmax(outputs, dim=1), 1).indices\n",
    "                # correct += (predicted == labels.max(1).indices).sum().div(torch.numel(predicted)).item()\n",
    "                val_steps += 1\n",
    "\n",
    "# Here we save a checkpoint. It is automatically registered with\n",
    "        # Ray Tune and will potentially be accessed through in ``get_checkpoint()``\n",
    "        # in future iterations.\n",
    "        # Note to save a file like checkpoint, you still need to put it under a directory\n",
    "        # to construct a checkpoint.\n",
    "        with tempfile.TemporaryDirectory() as temp_checkpoint_dir:\n",
    "            path = os.path.join(temp_checkpoint_dir, \"checkpoint.pt\")\n",
    "            torch.save(\n",
    "                (net.state_dict(), optimizer.state_dict()), path\n",
    "            )\n",
    "            checkpoint = Checkpoint.from_directory(temp_checkpoint_dir)\n",
    "            train.report(\n",
    "                {\"loss\": (val_loss / val_steps), \n",
    "                #  \"accuracy\": (correct / val_steps)\n",
    "                 },\n",
    "                checkpoint=checkpoint,\n",
    "            )\n",
    "    print(\"Finished Training\")\n",
    "\n",
    "def test_best_model(best_result):\n",
    "    best_trained_model, _, testset = load_data(dataDir, best_result.config)\n",
    "\n",
    "    checkpoint_path = os.path.join(best_result.checkpoint.to_directory(), \"checkpoint.pt\")\n",
    "\n",
    "    model_state, _ = torch.load(checkpoint_path)\n",
    "    best_trained_model.load_state_dict(model_state)\n",
    "\n",
    "    testloader = DataLoader( testset, batch_size=128, \n",
    "                            shuffle=False, num_workers=4)\n",
    "\n",
    "    correct = 0; total = 0; loss = 0\n",
    "    best_trained_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs,_ in testloader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = best_trained_model(inputs)\n",
    "            outputs = outputs.detach().squeeze().float()\n",
    "            loss += criterion(outputs, inputs.squeeze()).cpu().numpy()\n",
    "            # predicted = torch.max(F.softmax(outputs, dim=1), 1).indices\n",
    "            # correct += (predicted == labels.max(1).indices).sum().div(torch.numel(predicted)).item()\n",
    "            total += 1\n",
    "    # print(\"Best trial test set accuracy for \\\"{}\\\": {}\".format(trainScheme, correct/total))\n",
    "    print(\"Best trial test set loss for \\\"{}\\\": {}\".format(trainScheme, loss/total))\n",
    "\n",
    "def main(num_samples=10, max_num_epochs=10, cpus_per_trial=6, gpus_per_trial=2):\n",
    "    config = {\n",
    "    \"lr\": tune.loguniform(1e-1, 5e-5),\n",
    "    \"latentSpace\": tune.choice([2, 4, 8, 16]),\n",
    "    # \"batch_size\": tune.choice([128, 256]),\n",
    "    \"wd\": tune.loguniform(1e-1, 1e-5),\n",
    "    # \"momentum\": tune.uniform(0.1, 1.0),\n",
    "    # \"amsgrad\": tune.choice([True, False]),\n",
    "    # \"dropout\": tune.uniform(0.0, 0.5),\n",
    "    }\n",
    "    print(modelName + \" with SGD for OP side:\"+str(side))\n",
    "    scheduler = ASHAScheduler(\n",
    "        max_t=max_num_epochs,\n",
    "        grace_period=1,\n",
    "        reduction_factor=2\n",
    "    )\n",
    "    tuner = tune.Tuner(\n",
    "         tune.with_resources(\n",
    "            tune.with_parameters(trainFN),\n",
    "            resources={\"cpu\": cpus_per_trial, \"gpu\": gpus_per_trial}\n",
    "        ),\n",
    "        tune_config=tune.TuneConfig(\n",
    "            metric=\"loss\",\n",
    "            mode=\"min\",\n",
    "            scheduler=scheduler,\n",
    "            num_samples=num_samples,\n",
    "        ),\n",
    "        param_space=config,\n",
    "    )\n",
    "    results = tuner.fit()\n",
    "    best_result = results.get_best_result(\"loss\", \"min\")\n",
    "\n",
    "    print(\"Best trial config: {}\".format(best_result.config))\n",
    "    print(\"Best trial final validation loss: {}\".format(\n",
    "        best_result.metrics[\"loss\"]))\n",
    "    # if nTargets > 1:\n",
    "    #     print(\"Best trial final validation accuracy: {}\".format(\n",
    "    #         best_result.metrics[\"accuracy\"]))\n",
    "    test_best_model(best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e773361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-10-06 17:18:57</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:10.49        </td></tr>\n",
       "<tr><td>Memory:      </td><td>8.7/31.3 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 64.000: None | Iter 32.000: None | Iter 16.000: None | Iter 8.000: None | Iter 4.000: None | Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 6.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 3<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainFN_c1040_00000</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2025-10-06_17-18-44_628543_71667/artifacts/2025-10-06_17-18-46/trainFN_2025-10-06_17-18-44/driver_artifacts/trainFN_c1040_00000_0_latentSpace=2,lr=0.0006,wd=0.0000_2025-10-06_17-18-46/error.txt</td></tr>\n",
       "<tr><td>trainFN_c1040_00001</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2025-10-06_17-18-44_628543_71667/artifacts/2025-10-06_17-18-46/trainFN_2025-10-06_17-18-44/driver_artifacts/trainFN_c1040_00001_1_latentSpace=4,lr=0.0146,wd=0.0325_2025-10-06_17-18-46/error.txt</td></tr>\n",
       "<tr><td>trainFN_c1040_00002</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2025-10-06_17-18-44_628543_71667/artifacts/2025-10-06_17-18-46/trainFN_2025-10-06_17-18-44/driver_artifacts/trainFN_c1040_00002_2_latentSpace=2,lr=0.0002,wd=0.0000_2025-10-06_17-18-46/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th>status  </th><th>loc                 </th><th style=\"text-align: right;\">  latentSpace</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">         wd</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainFN_c1040_00003</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">0.00322037 </td><td style=\"text-align: right;\">1.37085e-05</td></tr>\n",
       "<tr><td>trainFN_c1040_00004</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">0.000662406</td><td style=\"text-align: right;\">0.000122391</td></tr>\n",
       "<tr><td>trainFN_c1040_00005</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">           16</td><td style=\"text-align: right;\">0.00523295 </td><td style=\"text-align: right;\">0.00418077 </td></tr>\n",
       "<tr><td>trainFN_c1040_00006</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">           16</td><td style=\"text-align: right;\">0.0950636  </td><td style=\"text-align: right;\">0.000678475</td></tr>\n",
       "<tr><td>trainFN_c1040_00007</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">0.000173013</td><td style=\"text-align: right;\">0.00899187 </td></tr>\n",
       "<tr><td>trainFN_c1040_00008</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">            8</td><td style=\"text-align: right;\">0.00325957 </td><td style=\"text-align: right;\">0.000142657</td></tr>\n",
       "<tr><td>trainFN_c1040_00009</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">0.000130971</td><td style=\"text-align: right;\">0.00175306 </td></tr>\n",
       "<tr><td>trainFN_c1040_00010</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">           16</td><td style=\"text-align: right;\">0.000301984</td><td style=\"text-align: right;\">0.0202366  </td></tr>\n",
       "<tr><td>trainFN_c1040_00011</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">0.00061134 </td><td style=\"text-align: right;\">8.52108e-05</td></tr>\n",
       "<tr><td>trainFN_c1040_00012</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">0.0314486  </td><td style=\"text-align: right;\">0.000658477</td></tr>\n",
       "<tr><td>trainFN_c1040_00013</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">0.0166848  </td><td style=\"text-align: right;\">4.81895e-05</td></tr>\n",
       "<tr><td>trainFN_c1040_00014</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">0.000172798</td><td style=\"text-align: right;\">0.00831374 </td></tr>\n",
       "<tr><td>trainFN_c1040_00015</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">           16</td><td style=\"text-align: right;\">0.0890773  </td><td style=\"text-align: right;\">0.000469976</td></tr>\n",
       "<tr><td>trainFN_c1040_00016</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">           16</td><td style=\"text-align: right;\">0.00479643 </td><td style=\"text-align: right;\">0.000340285</td></tr>\n",
       "<tr><td>trainFN_c1040_00017</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">           16</td><td style=\"text-align: right;\">0.00109608 </td><td style=\"text-align: right;\">0.0231706  </td></tr>\n",
       "<tr><td>trainFN_c1040_00018</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">            8</td><td style=\"text-align: right;\">0.0385781  </td><td style=\"text-align: right;\">3.87872e-05</td></tr>\n",
       "<tr><td>trainFN_c1040_00019</td><td>PENDING </td><td>                    </td><td style=\"text-align: right;\">           16</td><td style=\"text-align: right;\">0.00139121 </td><td style=\"text-align: right;\">0.0337412  </td></tr>\n",
       "<tr><td>trainFN_c1040_00000</td><td>ERROR   </td><td>134.109.17.190:82809</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">0.000611678</td><td style=\"text-align: right;\">3.36925e-05</td></tr>\n",
       "<tr><td>trainFN_c1040_00001</td><td>ERROR   </td><td>134.109.17.190:82919</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">0.0146436  </td><td style=\"text-align: right;\">0.0325457  </td></tr>\n",
       "<tr><td>trainFN_c1040_00002</td><td>ERROR   </td><td>134.109.17.190:83001</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">0.00017794 </td><td style=\"text-align: right;\">4.01279e-05</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 17:18:49,710\tERROR tune_controller.py:1331 -- Trial task failed for trial trainFN_c1040_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=82809, ip=134.109.17.190, actor_id=a811908a51694e4f60c4e3a401000000, repr=trainFN)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 104, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_71667/2468403016.py\", line 218, in trainFN\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 733, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1515, in _next_data\n",
      "    return self._process_data(data, worker_id)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1550, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/_utils.py\", line 750, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n",
      "    return self.collate_fn(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 211, in collate\n",
      "    return [\n",
      "           ^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 212, in <listcomp>\n",
      "    collate(samples, collate_fn_map=collate_fn_map)\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 272, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: stack expects each tensor to be equal size, but got [1] at entry 0 and [0] at entry 1\n",
      "2025-10-06 17:18:53,366\tERROR tune_controller.py:1331 -- Trial task failed for trial trainFN_c1040_00001\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=82919, ip=134.109.17.190, actor_id=70ec2caece97c9926adfb7dc01000000, repr=trainFN)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 104, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_71667/2468403016.py\", line 218, in trainFN\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 733, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1515, in _next_data\n",
      "    return self._process_data(data, worker_id)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1550, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/_utils.py\", line 750, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n",
      "    return self.collate_fn(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 211, in collate\n",
      "    return [\n",
      "           ^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 212, in <listcomp>\n",
      "    collate(samples, collate_fn_map=collate_fn_map)\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 272, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: stack expects each tensor to be equal size, but got [1] at entry 0 and [2] at entry 2\n",
      "2025-10-06 17:18:56,385\tERROR tune_controller.py:1331 -- Trial task failed for trial trainFN_c1040_00002\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/_private/worker.py\", line 2753, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/_private/worker.py\", line 904, in get_objects\n",
      "    raise value.as_instanceof_cause()\n",
      "ray.exceptions.RayTaskError(RuntimeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=83001, ip=134.109.17.190, actor_id=ed1be6b7cf2987998945bca801000000, repr=trainFN)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
      "    raise skipped from exception_cause(skipped)\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/air/_internal/util.py\", line 104, in run\n",
      "    self._ret = self._target(*self._args, **self._kwargs)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
      "    training_func=lambda: self._trainable_func(self.config),\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
      "    output = fn()\n",
      "             ^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/tune/trainable/util.py\", line 130, in inner\n",
      "    return trainable(config, **fn_kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_71667/2468403016.py\", line 218, in trainFN\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 733, in __next__\n",
      "    data = self._next_data()\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1515, in _next_data\n",
      "    return self._process_data(data, worker_id)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1550, in _process_data\n",
      "    data.reraise()\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/_utils.py\", line 750, in reraise\n",
      "    raise exception\n",
      "RuntimeError: Caught RuntimeError in DataLoader worker process 0.\n",
      "Original Traceback (most recent call last):\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/worker.py\", line 349, in _worker_loop\n",
      "    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n",
      "    return self.collate_fn(data)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 398, in default_collate\n",
      "    return collate(batch, collate_fn_map=default_collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 211, in collate\n",
      "    return [\n",
      "           ^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 212, in <listcomp>\n",
      "    collate(samples, collate_fn_map=collate_fn_map)\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n",
      "    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/shashank/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/utils/data/_utils/collate.py\", line 272, in collate_tensor_fn\n",
      "    return torch.stack(batch, 0, out=out)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "RuntimeError: stack expects each tensor to be equal size, but got [1] at entry 0 and [2] at entry 2\n",
      "2025-10-06 17:18:57,397\tWARNING tune.py:219 -- Stop signal received (e.g. via SIGINT/Ctrl+C), ending Ray Tune run. This will try to checkpoint the experiment state one last time. Press CTRL+C (or send SIGINT/SIGKILL/SIGTERM) to skip. \n",
      "2025-10-06 17:18:57,399\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/shashank/ray_results/trainFN_2025-10-06_17-18-44' in 0.0020s.\n",
      "2025-10-06 17:18:58,971\tERROR tune.py:1037 -- Trials did not complete: [trainFN_c1040_00000, trainFN_c1040_00001, trainFN_c1040_00002]\n",
      "2025-10-06 17:18:58,972\tINFO tune.py:1041 -- Total run time: 12.09 seconds (10.49 seconds for the tuning loop).\n",
      "2025-10-06 17:18:58,972\tWARNING tune.py:1056 -- Experiment has been interrupted, but the most recent state was saved.\n",
      "Resume experiment with: Tuner.restore(path=\"/home/shashank/ray_results/trainFN_2025-10-06_17-18-44\", trainable=...)\n",
      "2025-10-06 17:18:58,977\tWARNING experiment_analysis.py:180 -- Failed to fetch metrics for 17 trial(s):\n",
      "- trainFN_c1040_00003: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00003: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00003_3_latentSpace=2,lr=0.0032,wd=0.0000_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00004: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00004: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00004_4_latentSpace=2,lr=0.0007,wd=0.0001_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00005: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00005: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00005_5_latentSpace=16,lr=0.0052,wd=0.0042_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00006: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00006: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00006_6_latentSpace=16,lr=0.0951,wd=0.0007_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00007: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00007: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00007_7_latentSpace=4,lr=0.0002,wd=0.0090_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00008: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00008: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00008_8_latentSpace=8,lr=0.0033,wd=0.0001_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00009: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00009: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00009_9_latentSpace=4,lr=0.0001,wd=0.0018_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00010: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00010: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00010_10_latentSpace=16,lr=0.0003,wd=0.0202_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00011: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00011: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00011_11_latentSpace=2,lr=0.0006,wd=0.0001_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00012: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00012: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00012_12_latentSpace=2,lr=0.0314,wd=0.0007_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00013: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00013: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00013_13_latentSpace=2,lr=0.0167,wd=0.0000_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00014: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00014: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00014_14_latentSpace=2,lr=0.0002,wd=0.0083_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00015: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00015: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00015_15_latentSpace=16,lr=0.0891,wd=0.0005_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00016: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00016: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00016_16_latentSpace=16,lr=0.0048,wd=0.0003_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00017: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00017: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00017_17_latentSpace=16,lr=0.0011,wd=0.0232_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00018: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00018: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00018_18_latentSpace=8,lr=0.0386,wd=0.0000_2025-10-06_17-18-46')\n",
      "- trainFN_c1040_00019: FileNotFoundError('Could not fetch metrics for trainFN_c1040_00019: both result.json and progress.csv were not found at /home/shashank/ray_results/trainFN_2025-10-06_17-18-44/trainFN_c1040_00019_19_latentSpace=16,lr=0.0014,wd=0.0337_2025-10-06_17-18-46')\n",
      "2025-10-06 17:18:58,978\tWARNING experiment_analysis.py:558 -- Could not find best trial. Did you pass the correct `metric` parameter?\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No best trial found for the given metric: loss. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m main(num_samples=\u001b[32m20\u001b[39m, max_num_epochs=\u001b[32m100\u001b[39m, gpus_per_trial=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 333\u001b[39m, in \u001b[36mmain\u001b[39m\u001b[34m(num_samples, max_num_epochs, cpus_per_trial, gpus_per_trial)\u001b[39m\n\u001b[32m    319\u001b[39m tuner = tune.Tuner(\n\u001b[32m    320\u001b[39m      tune.with_resources(\n\u001b[32m    321\u001b[39m         tune.with_parameters(trainFN),\n\u001b[32m   (...)\u001b[39m\u001b[32m    330\u001b[39m     param_space=config,\n\u001b[32m    331\u001b[39m )\n\u001b[32m    332\u001b[39m results = tuner.fit()\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m best_result = results.get_best_result(\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmin\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    335\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest trial config: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(best_result.config))\n\u001b[32m    336\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest trial final validation loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m\"\u001b[39m.format(\n\u001b[32m    337\u001b[39m     best_result.metrics[\u001b[33m\"\u001b[39m\u001b[33mloss\u001b[39m\u001b[33m\"\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralnets/lib/python3.11/site-packages/ray/tune/result_grid.py:161\u001b[39m, in \u001b[36mResultGrid.get_best_result\u001b[39m\u001b[34m(self, metric, mode, scope, filter_nan_and_inf)\u001b[39m\n\u001b[32m    150\u001b[39m     error_msg = (\n\u001b[32m    151\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mNo best trial found for the given metric: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    152\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m._experiment_analysis.default_metric\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    153\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThis means that no trial has reported this metric\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    154\u001b[39m     )\n\u001b[32m    155\u001b[39m     error_msg += (\n\u001b[32m    156\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m, or all values reported for this metric are NaN. To not ignore NaN \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mvalues, you can set the `filter_nan_and_inf` arg to False.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m filter_nan_and_inf\n\u001b[32m    159\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    160\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(error_msg)\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._trial_to_result(best_trial)\n",
      "\u001b[31mRuntimeError\u001b[39m: No best trial found for the given metric: loss. This means that no trial has reported this metric, or all values reported for this metric are NaN. To not ignore NaN values, you can set the `filter_nan_and_inf` arg to False."
     ]
    }
   ],
   "source": [
    "main(num_samples=20, max_num_epochs=100, gpus_per_trial=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec2527af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-10-06 11:02:08</td></tr>\n",
       "<tr><td>Running for: </td><td>00:02:09.46        </td></tr>\n",
       "<tr><td>Memory:      </td><td>8.7/31.3 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=19<br>Bracket: Iter 64.000: None | Iter 32.000: -0.4327083230018616 | Iter 16.000: -0.47205379605293274 | Iter 8.000: -0.5657111406326294 | Iter 4.000: -0.5650091171264648 | Iter 2.000: -0.6237573623657227 | Iter 1.000: -0.6903272867202759<br>Logical resource usage: 6.0/12 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  latentSpace</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">         wd</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>trainFN_d6512_00000</td><td>TERMINATED</td><td>134.109.17.190:61138</td><td style=\"text-align: right;\">            8</td><td style=\"text-align: right;\">0.00751988 </td><td style=\"text-align: right;\">0.00112144 </td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">       22.9955  </td><td style=\"text-align: right;\">0.409437</td></tr>\n",
       "<tr><td>trainFN_d6512_00001</td><td>TERMINATED</td><td>134.109.17.190:62711</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">0.00107592 </td><td style=\"text-align: right;\">0.000130657</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        1.32387 </td><td style=\"text-align: right;\">0.606898</td></tr>\n",
       "<tr><td>trainFN_d6512_00002</td><td>TERMINATED</td><td>134.109.17.190:62835</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">0.0643911  </td><td style=\"text-align: right;\">0.0593757  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        1.27687 </td><td style=\"text-align: right;\">0.698435</td></tr>\n",
       "<tr><td>trainFN_d6512_00003</td><td>TERMINATED</td><td>134.109.17.190:62960</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">0.000226522</td><td style=\"text-align: right;\">0.00424682 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.875912</td><td style=\"text-align: right;\">0.705201</td></tr>\n",
       "<tr><td>trainFN_d6512_00004</td><td>TERMINATED</td><td>134.109.17.190:63054</td><td style=\"text-align: right;\">           16</td><td style=\"text-align: right;\">0.0270434  </td><td style=\"text-align: right;\">0.00298424 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        1.2869  </td><td style=\"text-align: right;\">0.75934 </td></tr>\n",
       "<tr><td>trainFN_d6512_00005</td><td>TERMINATED</td><td>134.109.17.190:63179</td><td style=\"text-align: right;\">            8</td><td style=\"text-align: right;\">0.00766128 </td><td style=\"text-align: right;\">2.23199e-05</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.884244</td><td style=\"text-align: right;\">0.697429</td></tr>\n",
       "<tr><td>trainFN_d6512_00006</td><td>TERMINATED</td><td>134.109.17.190:63273</td><td style=\"text-align: right;\">            8</td><td style=\"text-align: right;\">9.20462e-05</td><td style=\"text-align: right;\">0.0145525  </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        1.27778 </td><td style=\"text-align: right;\">0.695723</td></tr>\n",
       "<tr><td>trainFN_d6512_00007</td><td>TERMINATED</td><td>134.109.17.190:63397</td><td style=\"text-align: right;\">            8</td><td style=\"text-align: right;\">0.000220383</td><td style=\"text-align: right;\">7.74112e-05</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        2.23773 </td><td style=\"text-align: right;\">0.567568</td></tr>\n",
       "<tr><td>trainFN_d6512_00008</td><td>TERMINATED</td><td>134.109.17.190:63582</td><td style=\"text-align: right;\">            8</td><td style=\"text-align: right;\">7.70759e-05</td><td style=\"text-align: right;\">0.000955027</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.88641 </td><td style=\"text-align: right;\">0.697493</td></tr>\n",
       "<tr><td>trainFN_d6512_00009</td><td>TERMINATED</td><td>134.109.17.190:63676</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">0.0847155  </td><td style=\"text-align: right;\">0.000468349</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.821227</td><td style=\"text-align: right;\">0.723539</td></tr>\n",
       "<tr><td>trainFN_d6512_00010</td><td>TERMINATED</td><td>134.109.17.190:63771</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">0.00265024 </td><td style=\"text-align: right;\">0.0016663  </td><td style=\"text-align: right;\">    32</td><td style=\"text-align: right;\">       14.939   </td><td style=\"text-align: right;\">0.472786</td></tr>\n",
       "<tr><td>trainFN_d6512_00011</td><td>TERMINATED</td><td>134.109.17.190:64802</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">0.00236896 </td><td style=\"text-align: right;\">0.00594925 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        2.23391 </td><td style=\"text-align: right;\">1.07226 </td></tr>\n",
       "<tr><td>trainFN_d6512_00012</td><td>TERMINATED</td><td>134.109.17.190:65215</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">0.000740862</td><td style=\"text-align: right;\">2.18351e-05</td><td style=\"text-align: right;\">    16</td><td style=\"text-align: right;\">        7.70413 </td><td style=\"text-align: right;\">0.507917</td></tr>\n",
       "<tr><td>trainFN_d6512_00013</td><td>TERMINATED</td><td>134.109.17.190:65761</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">0.000682479</td><td style=\"text-align: right;\">0.00377321 </td><td style=\"text-align: right;\">     8</td><td style=\"text-align: right;\">        4.04251 </td><td style=\"text-align: right;\">0.6064  </td></tr>\n",
       "<tr><td>trainFN_d6512_00014</td><td>TERMINATED</td><td>134.109.17.190:66067</td><td style=\"text-align: right;\">            8</td><td style=\"text-align: right;\">0.0972757  </td><td style=\"text-align: right;\">0.000686492</td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        1.35426 </td><td style=\"text-align: right;\">0.747307</td></tr>\n",
       "<tr><td>trainFN_d6512_00015</td><td>TERMINATED</td><td>134.109.17.190:66191</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">0.00255    </td><td style=\"text-align: right;\">0.00626241 </td><td style=\"text-align: right;\">     2</td><td style=\"text-align: right;\">        1.33475 </td><td style=\"text-align: right;\">0.649449</td></tr>\n",
       "<tr><td>trainFN_d6512_00016</td><td>TERMINATED</td><td>134.109.17.190:66316</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">0.0324579  </td><td style=\"text-align: right;\">0.00358317 </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.869153</td><td style=\"text-align: right;\">0.706808</td></tr>\n",
       "<tr><td>trainFN_d6512_00017</td><td>TERMINATED</td><td>134.109.17.190:66410</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">0.0119617  </td><td style=\"text-align: right;\">0.00717886 </td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        2.23586 </td><td style=\"text-align: right;\">0.734935</td></tr>\n",
       "<tr><td>trainFN_d6512_00018</td><td>TERMINATED</td><td>134.109.17.190:66595</td><td style=\"text-align: right;\">            2</td><td style=\"text-align: right;\">0.0516998  </td><td style=\"text-align: right;\">0.0175771  </td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.876787</td><td style=\"text-align: right;\">0.708569</td></tr>\n",
       "<tr><td>trainFN_d6512_00019</td><td>TERMINATED</td><td>134.109.17.190:66690</td><td style=\"text-align: right;\">            4</td><td style=\"text-align: right;\">0.013183   </td><td style=\"text-align: right;\">0.000423239</td><td style=\"text-align: right;\">     4</td><td style=\"text-align: right;\">        2.24293 </td><td style=\"text-align: right;\">0.806027</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-06 11:02:08,768\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/shashank/ray_results/trainFN_2025-10-06_10-59-59' in 0.0050s.\n",
      "2025-10-06 11:02:08,772\tINFO tune.py:1041 -- Total run time: 129.47 seconds (129.45 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best trial config: {'lr': 0.007519875551227198, 'latentSpace': 8, 'wd': 0.0011214449822134858}\n",
      "Best trial final validation loss: 0.40943703055381775\n",
      "Best trial test set loss for \"Autoencoder\": 0.38199755549430847\n"
     ]
    }
   ],
   "source": [
    "main(num_samples=20, max_num_epochs=100, gpus_per_trial=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4b021fe0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 16 elements not 64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     37\u001b[39m trainset = ds.CustomAutoencoderDataset(dataDir+\u001b[33m\"\u001b[39m\u001b[33mtestPUD\u001b[39m\u001b[33m\"\u001b[39m, side, transform)\n\u001b[32m     38\u001b[39m data_loader = torch.utils.data.DataLoader(trainset, batch_size=\u001b[32m10\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m visualize_reconstruction(model, data_loader, side)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mvisualize_reconstruction\u001b[39m\u001b[34m(model, data_loader, side)\u001b[39m\n\u001b[32m     16\u001b[39m images, _ = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(data_loader))\n\u001b[32m     17\u001b[39m images = images.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m reconstructed = model(images)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Plot original vs reconstructed images\u001b[39;00m\n\u001b[32m     21\u001b[39m fig, axes = plt.subplots(\u001b[32m2\u001b[39m, \u001b[32m8\u001b[39m, figsize=(\u001b[32m15\u001b[39m, \u001b[32m4\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[44]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mConvAutoencoder.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     54\u001b[39m x = \u001b[38;5;28mself\u001b[39m.fc_dec(z)\n\u001b[32m     55\u001b[39m x = x.view(x.size(\u001b[32m0\u001b[39m), \u001b[32m32\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m4\u001b[39m)  \u001b[38;5;66;03m# reshape back\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m x = \u001b[38;5;28mself\u001b[39m.decoder(x)\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/nn/modules/container.py:240\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m         \u001b[38;5;28minput\u001b[39m = module(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/nn/modules/batchnorm.py:193\u001b[39m, in \u001b[36m_BatchNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    186\u001b[39m     bn_training = (\u001b[38;5;28mself\u001b[39m.running_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.running_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    188\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[33;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[33;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[32m    191\u001b[39m \u001b[33;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m F.batch_norm(\n\u001b[32m    194\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m    195\u001b[39m     \u001b[38;5;66;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;00m\n\u001b[32m    196\u001b[39m     \u001b[38;5;28mself\u001b[39m.running_mean\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.track_running_stats\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    199\u001b[39m     \u001b[38;5;28mself\u001b[39m.running_var \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.training \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.track_running_stats \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    200\u001b[39m     \u001b[38;5;28mself\u001b[39m.weight,\n\u001b[32m    201\u001b[39m     \u001b[38;5;28mself\u001b[39m.bias,\n\u001b[32m    202\u001b[39m     bn_training,\n\u001b[32m    203\u001b[39m     exponential_average_factor,\n\u001b[32m    204\u001b[39m     \u001b[38;5;28mself\u001b[39m.eps,\n\u001b[32m    205\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralnets/lib/python3.11/site-packages/torch/nn/functional.py:2822\u001b[39m, in \u001b[36mbatch_norm\u001b[39m\u001b[34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[39m\n\u001b[32m   2819\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[32m   2820\u001b[39m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m.size())\n\u001b[32m-> \u001b[39m\u001b[32m2822\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.batch_norm(\n\u001b[32m   2823\u001b[39m     \u001b[38;5;28minput\u001b[39m,\n\u001b[32m   2824\u001b[39m     weight,\n\u001b[32m   2825\u001b[39m     bias,\n\u001b[32m   2826\u001b[39m     running_mean,\n\u001b[32m   2827\u001b[39m     running_var,\n\u001b[32m   2828\u001b[39m     training,\n\u001b[32m   2829\u001b[39m     momentum,\n\u001b[32m   2830\u001b[39m     eps,\n\u001b[32m   2831\u001b[39m     torch.backends.cudnn.enabled,\n\u001b[32m   2832\u001b[39m )\n",
      "\u001b[31mRuntimeError\u001b[39m: running_mean should contain 16 elements not 64"
     ]
    }
   ],
   "source": [
    "model = ConvAutoencoder(8).to(device)\n",
    "# model = custNN.Autoencoder([900, 750, 600, 450, 300, 150, 75, 30, 10, 2], nn.Tanh(), nn.Tanh())\n",
    "# model.load_state_dict(torch.load(data_dir+f\"checkpoints/Autoencoder/\"+date+\"/2/model_epoch_60.pth\", map_location=device))\n",
    "# model.load_state_dict(torch.load(data_dir+f\"checkpoints/Autoencoder/model.pth\", map_location=device))\n",
    "\n",
    "side = 32\n",
    "class ReshapeTransform:\n",
    "    def __init__(self, shape):\n",
    "        self.shape = shape\n",
    "    def __call__(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "def visualize_reconstruction(model, data_loader, side=30):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        images, _ = next(iter(data_loader))\n",
    "        images = images.to(device)\n",
    "        reconstructed = model(images)\n",
    "\n",
    "        # Plot original vs reconstructed images\n",
    "        fig, axes = plt.subplots(2, 8, figsize=(15, 4))\n",
    "        for i in range(8):\n",
    "            # Original images\n",
    "            axes[0,i].imshow(images[i].cpu().numpy().squeeze().reshape(side, side), cmap='gray')\n",
    "            axes[0,i].axis('off')\n",
    "\n",
    "            # Reconstructed images\n",
    "            axes[1,i].imshow(reconstructed[i].cpu().numpy().squeeze().reshape(side, side), cmap='gray')\n",
    "            axes[1,i].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "transform = ReshapeTransform((1, side, side)) # v2.Compose([v2.Lambda(lambda x: 2*x - 1)]) # None #\n",
    "trainset = ds.CustomAutoencoderDataset(dataDir+\"testPUD\", side, transform)\n",
    "data_loader = torch.utils.data.DataLoader(trainset, batch_size=10, shuffle=True)\n",
    "\n",
    "visualize_reconstruction(model, data_loader, side)\n",
    "# visualize_reconstruction(model,  smallTrainLoader)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ee099c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5116f38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "transform = None\n",
    "dataset = ds.CustomAutoencoderDataset(dataDir+\"small2DGH32\", side, transform) # 2DGH32 gnhd2dTest\n",
    "data_loader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "# model = ConvAutoencoder(8).to(device)\n",
    "# model.eval()\n",
    "with torch.no_grad():\n",
    "    images, _ = next(iter(data_loader))\n",
    "    # images = images.to(device)\n",
    "    # reconstructed = model(images)\n",
    "    print(images[0].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "993be808",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../assets/astronaut.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     12\u001b[39m torch.manual_seed(\u001b[32m0\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# If you're trying to run that on Colab, you can download the assets and the\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# helpers from https://github.com/pytorch/vision/tree/main/gallery/\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m orig_img = Image.open(Path(\u001b[33m'\u001b[39m\u001b[33m../assets\u001b[39m\u001b[33m'\u001b[39m) / \u001b[33m'\u001b[39m\u001b[33mastronaut.jpg\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/neuralnets/lib/python3.11/site-packages/PIL/Image.py:3465\u001b[39m, in \u001b[36mopen\u001b[39m\u001b[34m(fp, mode, formats)\u001b[39m\n\u001b[32m   3462\u001b[39m     filename = os.fspath(fp)\n\u001b[32m   3464\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[32m-> \u001b[39m\u001b[32m3465\u001b[39m     fp = builtins.open(filename, \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   3466\u001b[39m     exclusive_fp = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   3467\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '../assets/astronaut.jpg'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torchvision.transforms import v2\n",
    "\n",
    "plt.rcParams[\"savefig.bbox\"] = 'tight'\n",
    "\n",
    "# if you change the seed, make sure that the randomly-applied transforms\n",
    "# properly show that the image can be both transformed and *not* transformed!\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# If you're trying to run that on Colab, you can download the assets and the\n",
    "# helpers from https://github.com/pytorch/vision/tree/main/gallery/\n",
    "\n",
    "orig_img = Image.open(Path('../assets') / 'astronaut.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "965049ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import networks as custNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "761826e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder(\n",
      "  (encoder): Sequential(\n",
      "    (0): Linear(in_features=900, out_features=750, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=750, out_features=600, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=600, out_features=450, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=450, out_features=300, bias=True)\n",
      "    (7): Tanh()\n",
      "    (8): Linear(in_features=300, out_features=150, bias=True)\n",
      "    (9): Tanh()\n",
      "    (10): Linear(in_features=150, out_features=75, bias=True)\n",
      "    (11): Tanh()\n",
      "    (12): Linear(in_features=75, out_features=30, bias=True)\n",
      "    (13): Tanh()\n",
      "    (14): Linear(in_features=30, out_features=10, bias=True)\n",
      "    (15): Tanh()\n",
      "    (16): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      "  (decoder): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=10, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=10, out_features=30, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=30, out_features=75, bias=True)\n",
      "    (5): Tanh()\n",
      "    (6): Linear(in_features=75, out_features=150, bias=True)\n",
      "    (7): Tanh()\n",
      "    (8): Linear(in_features=150, out_features=300, bias=True)\n",
      "    (9): Tanh()\n",
      "    (10): Linear(in_features=300, out_features=450, bias=True)\n",
      "    (11): Tanh()\n",
      "    (12): Linear(in_features=450, out_features=600, bias=True)\n",
      "    (13): Tanh()\n",
      "    (14): Linear(in_features=600, out_features=750, bias=True)\n",
      "    (15): Tanh()\n",
      "    (16): Linear(in_features=750, out_features=900, bias=True)\n",
      "    (17): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = custNN.Autoencoder([900, 750, 600, 450, 300, 150, 75, 30, 10, 2], nn.Tanh(), nn.Tanh())\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "381d9473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0005"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f505cd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilsTrainTest import visualize_reconstruction\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as v2\n",
    "side = 28\n",
    "model = custNN.Autoencoder([784, 600, 450, 300, 150, 75, 30, 10, 2], nn.Tanh(), nn.Tanh())\n",
    "model.load_state_dict(torch.load(\"/home/shashank/Code/gonihedric/data/checkpoints/modelSecond.pth\", map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "transform = v2.Compose([\n",
    "    v2.ToTensor(),\n",
    "    v2.Lambda(lambda x: 2*x - 1),\n",
    "    ReshapeTransform((1, side*side))\n",
    "    # v2.Lambda(lambda x: torch.flatten(x, start_dim=1)),  # Flatten the image\n",
    "    # v2.Normalize((0.1307,), (0.3081,)),\n",
    "    # v2.Normalize((0.5,), (0.5,)),\n",
    "    # v2.Lambda(lambda x: x.view(-1) - 0.5)\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    transform=transform,\n",
    "    download=True\n",
    ")\n",
    "test_dataset = datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    transform=transform\n",
    ")\n",
    "batchSize = 10\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batchSize, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batchSize, shuffle=False)\n",
    "visualize_reconstruction(model, device, train_loader, side, location=\"/home/shashank/Code/gonihedric/data/checkpoints\")\n",
    "visualize_reconstruction(model, device, test_loader, side, location=\"/home/shashank/Code/gonihedric/data/checkpoints\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc91a67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b69a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
